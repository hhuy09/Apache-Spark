{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import sys\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "from pyspark.mllib.linalg import SparseVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating an RDD of LabeledPoint Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để xây dựng một ví dụ về bộ phân loại cây quyết định bằng cách sử dụng tập dữ liệu huấn luyện,trước tiên bạn cần phải tạo một RDD gồm LabeledPoint (pyspark.mllib.regression.LabeledPoint) các đối tượng. MỘTĐối tượng LabeledPoint chứa thuộc tính nhãn hoặc lớp cho một trường hợp,cùng với các thuộc tính cá thể liên quan.\n",
    "\n",
    "Thuộc tính đối tượng LabeledPoint phải là giá trị float hoặc các đối tượng có thểđược chuyển đổi thành các giá trị float, chẳng hạn như Boolean hoặc int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "outlook = {\"sunny\": 0.0, \"overcast\": 1.0, \"rainy\": 2.0}\n",
    "labeledpoints = [\n",
    " LabeledPoint(0.0,[outlook[\"sunny\"],85,85,False]),\n",
    " LabeledPoint(0.0,[outlook[\"sunny\"],80,90,True]),\n",
    " LabeledPoint(1.0,[outlook[\"overcast\"],83,86,False]),\n",
    " LabeledPoint(1.0,[outlook[\"rainy\"],70,96,False]),\n",
    " LabeledPoint(1.0,[outlook[\"rainy\"],68,80,False]),\n",
    " LabeledPoint(1.0,[outlook[\"rainy\"],68,80,False]),\n",
    " LabeledPoint(1.0,[outlook[\"rainy\"],68,80,False]),\n",
    " LabeledPoint(0.0,[outlook[\"rainy\"],65,70,True]),\n",
    " LabeledPoint(1.0,[outlook[\"overcast\"],64,65,True]),\n",
    " LabeledPoint(0.0,[outlook[\"sunny\"],72,95,False]),\n",
    " LabeledPoint(1.0,[outlook[\"sunny\"],69,70,False]),\n",
    " LabeledPoint(1.0,[outlook[\"sunny\"],75,80,False]),\n",
    " LabeledPoint(1.0,[outlook[\"sunny\"],75,70,True]),\n",
    " LabeledPoint(1.0,[outlook[\"overcast\"],72,90,True]),\n",
    " LabeledPoint(1.0,[outlook[\"overcast\"],81,75,False]),\n",
    " LabeledPoint(0.0,[outlook[\"rainy\"],71,91,True])\n",
    " ]\n",
    "data = sc.parallelize(labeledpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [0.0,85.0,85.0,0.0]),\n",
       " LabeledPoint(0.0, [0.0,80.0,90.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,83.0,86.0,0.0]),\n",
       " LabeledPoint(1.0, [2.0,70.0,96.0,0.0]),\n",
       " LabeledPoint(1.0, [2.0,68.0,80.0,0.0]),\n",
       " LabeledPoint(1.0, [2.0,68.0,80.0,0.0]),\n",
       " LabeledPoint(1.0, [2.0,68.0,80.0,0.0]),\n",
       " LabeledPoint(0.0, [2.0,65.0,70.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,64.0,65.0,1.0]),\n",
       " LabeledPoint(0.0, [0.0,72.0,95.0,0.0]),\n",
       " LabeledPoint(1.0, [0.0,69.0,70.0,0.0]),\n",
       " LabeledPoint(1.0, [0.0,75.0,80.0,0.0]),\n",
       " LabeledPoint(1.0, [0.0,75.0,70.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,72.0,90.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,81.0,75.0,0.0]),\n",
       " LabeledPoint(0.0, [2.0,71.0,91.0,1.0])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a Decision Tree Model with Spark MLlib\n",
    "Sử dụng RDD chứa các đối tượng LabeledPoint được tạo, bạn bây giờ có thể đào tạo mô hình cây quyết định bằng cách sử dụng Hàm DecisionTree.trainClassifier() trong mllib Spark\n",
    "\n",
    "Hàm DecisionTree.trainClassifier () tạo một mô hình bằng cáchđào tạo dữ liệu, một bộ sưu tập song song các đối tượng LabeledPoint. Các đối số numClasses chỉ định có bao nhiêu lớp rời rạc để dự đoán; trong nàytrường hợp, nó là hai vì ví dụ chỉ đơn giản là dự đoán một kết quả nhị phân là có / không.Đối số categoricalFeaturesInfo là một từ điển hoặc bản đồ chỉ định đối tượng địa lý nào là phân loại và có bao nhiêu giá trị phân loại mỗi những tính năng đó có thể thực hiện. Trong trường hợp này, bạn cần hướng phương thức trainClassifier () mà các giá trị đại diện cho triển vọng danh mục rời rạc — ví dụ: \"nắng\" hoặc \"mưa\" hoặc \"u ám\".Bất kỳ tính năng nào không được chỉ định trong đối số categoricalFeaturesInfo được coi là liên tục."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeModel classifier of depth 4 with 13 nodes\n",
      "  If (feature 2 <= 82.5)\n",
      "   If (feature 1 <= 66.5)\n",
      "    If (feature 0 in {2.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 0 not in {2.0})\n",
      "     Predict: 1.0\n",
      "   Else (feature 1 > 66.5)\n",
      "    Predict: 1.0\n",
      "  Else (feature 2 > 82.5)\n",
      "   If (feature 0 in {0.0})\n",
      "    Predict: 0.0\n",
      "   Else (feature 0 not in {0.0})\n",
      "    If (feature 0 in {2.0})\n",
      "     If (feature 1 <= 70.5)\n",
      "      Predict: 1.0\n",
      "     Else (feature 1 > 70.5)\n",
      "      Predict: 0.0\n",
      "    Else (feature 0 not in {2.0})\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.tree import DecisionTree\n",
    "#categoricalFeaturesInfo = {}\n",
    "#model = DecisionTree.trainClassifier(data=data, numClasses=2, categoricalFeaturesInfo=categoricalFeaturesInfo)\n",
    "model = DecisionTree.trainClassifier(data=data,\n",
    " numClasses=2,\n",
    " categoricalFeaturesInfo={0: 3})\n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a Spark MLlib Decision Tree Model to Classify New Data\n",
    "Dầu vào outlook = \"overcast\",nhiệt độ = 85, độ ẩm = 85 và gió = có, quyết định chơi là 1,0 --> đi chơi golf. Điều này tuân theo logic từ cây quyết định bạn đã tạo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([outlook[\"overcast\"],85,85,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing a Naive Bayes Classifier Using Spark MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "model = NaiveBayes.train(data=data, lambda_=1.0)\n",
    "model.predict([1.0,85,85,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering Using Spark MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Implementing a Recommender Using Spark MLlib\n",
    "Exercise: Implementing a Recommender Using Spark MLlib\n",
    "\n",
    "Tập dữ liệu chứa 100.000 xếp hạng bởi 943 người dùng trên 1.682 mục, với mỗi người dùng đã xếp hạng ít nhất 20 phim.\n",
    "\n",
    "user id | item id | rating | timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required MLlib libraries:\n",
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.recommendation \\\n",
    "import ALS, MatrixFactorizationModel, Rating\n",
    "conf = SparkConf().setAppName('Movielens Recommender')\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['196', '242', '3', '881250949']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the Movielens dataset and create an RDD containing Rating objects:\n",
    "data = sc.textFile('data/movielens.csv')\n",
    "ratings = data.map(lambda x: x.split(','))\n",
    "ratings.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating(user=196, product=242, rating=3.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.textFile('data/movielens.dat')\n",
    "ratings = data.map(lambda x: x.split('\\t')) \\\n",
    " .map(lambda x: Rating(int(x[0]), int(x[1]), float(x[2]))) #Bỏ qua timestamp\n",
    "ratings.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a model using the ALS algorithm:\n",
    "rank = 10\n",
    "numIterations = 10\n",
    "model = ALS.train(ratings, rank, numIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý rằng rank và numIterations là các tham số điều chỉnh thuật toán;Rank là số lượng các yếu tố tiềm ẩn trong mô hình và numIterations là số lần lặp lại để chạy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ có thể kiểm tra mô hình dựa trên cùng một tập dữ liệu mà không cần rating(sử dụng mô hình để dự đoán thuộc tính này). Sau đó so sánh kết quả của dự đoán với xếp hạng thực tế để xác định sai số bình phương trung bình,đo độ chính xác của mô hình:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(196, 242), (186, 302), (22, 377), (244, 51), (166, 346)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = ratings.map(lambda p: (p[0], p[1]))\n",
    "testdata.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((316, 1084), 3.680324435930144),\n",
       " ((504, 1084), 4.3252875839772855),\n",
       " ((424, 1084), 5.020947172396465),\n",
       " ((541, 1084), 4.733278984846265),\n",
       " ((181, 1084), 1.8892183936344953)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predictAll(testdata) \\\n",
    " .map(lambda r: ((r[0], r[1]), r[2]))\n",
    "predictions.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((186, 302), (3.0, 3.3186171078919497)),\n",
       " ((115, 265), (2.0, 3.0859953266379687)),\n",
       " ((253, 465), (5.0, 4.270124091340714)),\n",
       " ((50, 246), (3.0, 3.3556865350317544)),\n",
       " ((225, 193), (4.0, 4.439608183164759))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratesAndPreds = ratings.map(lambda r: ((r[0], r[1]), r[2])) \\\n",
    " .join(predictions)\n",
    "ratesAndPreds.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.48192716404188984\n"
     ]
    }
   ],
   "source": [
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2) \\\n",
    " .mean()\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Để lưu mô hình để sử dụng với các đề xuất mới, hãy sử dụnghàm model.save()\n",
    "model.save(sc, \"ratings_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Triển khai mô hình dựa trên dữ liệu thời gian thực từ Spark DStream — sử dụng Hàm MatrixFactorizationModel.load()\n",
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "reloaded_model = MatrixFactorizationModel.load(sc, \"ratings_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.mllib.recommendation.MatrixFactorizationModel at 0x1b8fbba6190>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Using Spark MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a k-Means Clustering Model Using Spark MLlib\n",
    "\n",
    "Để triển khai k-means trong Spark, hãy sử dụng gói pyspark.mllib.clustering.KMeans.Trình bày cách đào tạo mô hình học máy phân cụm k-mean bằng cách sử dụng tập dữ liệu kmeans_data mẫu được cung cấp như một phần của bản phát hành Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0 0.0 0.0',\n",
       " '0.1 0.1 0.1',\n",
       " '0.2 0.2 0.2',\n",
       " '9.0 9.0 9.0',\n",
       " '9.1 9.1 9.1',\n",
       " '9.2 9.2 9.2']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and parse the data\n",
    "data = sc.textFile(\"data/mllib/kmeans_data.txt\")\n",
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0.]),\n",
       " array([0.1, 0.1, 0.1]),\n",
       " array([0.2, 0.2, 0.2]),\n",
       " array([9., 9., 9.]),\n",
       " array([9.1, 9.1, 9.1]),\n",
       " array([9.2, 9.2, 9.2])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsedData = data.map(lambda line: array( \\\n",
    " [float(x) for x in line.split(' ')]))\n",
    "parsedData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.mllib.clustering.KMeansModel at 0x219734565e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model (cluster the data)\n",
    "clusters = KMeans.train(parsedData, 2, maxIterations=10,initializationMode=\"random\")\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating a k-Means Clustering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate clustering by computing Within Set Sum of Squared Errors\n",
    "def error(point):\n",
    " center = clusters.centers[clusters.predict(point)]\n",
    " return sqrt(sum([x**2 for x in (point - center)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17320508075688776,\n",
       " 0.0,\n",
       " 0.17320508075688776,\n",
       " 0.17320508075688404,\n",
       " 3.076740298213702e-15,\n",
       " 0.1732050807568902]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSSSE = parsedData.map(lambda point: error(point))\n",
    "WSSSE.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "WSSSE = parsedData.map(lambda point: error(point)) \\\n",
    " .reduce(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set Sum of Squared Error = 0.6928203230275529\n"
     ]
    }
   ],
   "source": [
    "print(\"Within Set Sum of Squared Error = \" + str(WSSSE))\n",
    "# returns:\n",
    "# Within Set Sum of Squared Error = 0.692820323028"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Reloading a Clustering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load model\n",
    "clusters.save(sc, \"kmeans_model\")\n",
    "reloaded_model = KMeansModel.load(sc, \"kmeans_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
